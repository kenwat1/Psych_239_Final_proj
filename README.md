# Neural network representations of within-category variance 
## Introduction 
Moment to moment we are faced with an incoming flurry of complex information. However, we are able to effortlessly handle this onslaught of information by relying on our rich, highly structured conceptual system. Concepts are mental representations of the commonalities shared amongst a set of individuals belonging to the same category. Relationships between concepts are systematic and hierarchically-structured. This structure provides a powerful mechanism by which people are able to efficiently incorporate new information into preexisting knowledge and make appropriate generalizations across individuals both within and between categories. 
	Given the importance of this structure, how is it formed and sculpted with experience? Some have pointed to the role of early cognitive biases heavily guiding the process (Gelman & Medin, 1993) while others have suggested that this structure could entirely be a reflection of the statistical regularities experienced within the world (Lake et al. 2015; Saffran et al. 1996). Recent work using deep neural networks has provided insight into this question, replicating complex human behavior in categorization tasks without built-in explicit structure (Lake et al., 2015; Peterson et al., 2016; Saxe, 2018). This suggests that internalizing the environment’s structure via the detection of statistical regularities may be sufficient in building these complex conceptual structures. One aspect of the environment that may be particularly informative in building these structures is the experienced within-category coherence and variability. Some have suggested that sensitivity to within-category details may be crucial to the detection of statistical regularities across variable exemplars and to cueing the formation of a new category (Griffiths et al.,2007; Love et al., 2004; Rhodes & Gelman, 2008; Rhodes & Brickman, 2010). If this is the case, could representations of  category variability be partially responsible for neural networks’ human-like performance on categorization tasks? At first glance, this seems unlikely because the neural network is being trained to classify exemplars into certain categories, thus, the focus of attention will be on detection of between category differences as opposed to within-category details. However, Lake at al. (2015) were able to replicate human typicality ratings. Typicality ratings reflect the variability of individual exemplars within a category around a central prototype. The ability of the network to replicate human typicality ratings suggests that there is some prototype-like representation encoded in the network along with variation around that prototype. 
	The current work seeks to replicate and extend the work of Lake et al. (2015).They compare the performance of 3 different deep convolutional neural network architectures (OverFeat, AlexNet, GoogLeNet) in replicating human typicality judgements. Here, we consider the ResNet architecture along with AlexNet, and GoogLeNet. Along with using the outputs of these networks to compare to human typicality ratings, we also extract feature representations of exemplars to see if the networks can replicate similarity ratings between exemplars. 
  
## Methods

Human typicality and similarity ratings from 7 different categories were obtained from the Leuven Concept Database (De Deyne et al. 2008). 3 architectures were tested on their ability to predict these ratings. 

<img src="ty.png"
     alt="Markdown Monster icon"
     style="float: left; margin-right: 10px;" />

**Human behavioral data** <br>
From 112 undergraduates at the University of Leuven, typicality ratings and similarity ratings of 5-33 exemplars were obtained from 7 categories: birds, clothing, fish, fruit, insects, utensils, and mammals. Importantly, this dataset includes categories of both artifacts and natural kinds. There is evidence to suggest that artifacts and natural kinds may be represented in fundamentally different ways (e.g., Diesendruck & Gelman, 1999; Estes, 2003; Keil, 1989; Malt & Johnson, 1992). 

*Typicality Ratings*
Participants were given a list of exemplars with the category label printed at the top of the list. They were asked to indicate how typical, on a scale of 1 (very atypical) to 20 (very typical), each item was of the category printed at the top of the page.

*Similarity Ratings*
Pairwise similarity ratings were collected for all exemplar combinations within each category. Participants were asked to judge the similarity of every pair on a scale of 1 (totally dissimilar) to 20 (totally similar). 

**Convolutional Networks**  
We used three different architectures: AlexNet, GoogleNet, and ResNet18. AlexNet and GoogleNet were both found to provide good replication of human typicality judgements in Lake et al. (2015). ResNet18 was also included because of its superior classification performance over AlexNet and GoogleNet. All network’s were pre-trained on ImageNet. Pre-trained covnets classify inputs into 1 of 1000 categories. These categories are finer-grained than the ones available in the Leuven Concepts database, so the models were fine-tuned to categorize inputs into 1 of the 7 categories specified above. Images for fine-tuning were obtained by taking superclasses within the Imagenet database of the categories used in the Leuven Concepts database. 

Images used for typicality and similarity judgements were acquired by the following process. For each exemplar in the dataset an image was chosen via Google search. Images were chosen such that there was a single animal or object in clear view. To obtain an exemplar’s typicality rating, its image was fed into the network and the correct label’s probability was taken as the rating. A Spearman rank correlation was performed on the network’s typicality ratings and the average human typicality ratings. 

 To obtain pairwise within-category exemplar ratings, each exemplar’s feature embedding was extracted from the network and the cosine similarity between the feature embeddings was taken. Feature embeddings from AlexNet and GoogleNet were extracted from the final max pooling layers. Feature embeddings from ResNet18 were extracted from the average pooling layer. A Spearman rank correlation was performed on the network’s cosine similarity between exemplars and the average human pairwise exemplar similarity ratings.  
 
 

